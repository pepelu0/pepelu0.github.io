---
layout: post
title: 【翻译】非事务型分布式存储系统中的一致性
author: pepelu
date: 2019-09-10
online: false
tags:
    - 分布式
    - 一致性
---

***

原文地址: [Consistency in Non-Transactional Distributed Storage Systems](https://arxiv.org/pdf/1512.00168.pdf)

原作者: [Paolo Viotti](viotti@eurecom.fr) from EURECOM, [Marko Vukolic](mvu@zurich.ibm.com) from IBM Research - Zurich

***

# 摘要

近年来，关于分布式系统的讨论中，**一致性**这个词被赋予了不同的含义。在80年代，**一致性**的典型含义是**强一致性**，后来也叫**线性一致性**。近些年来，随着高可用性和扩展性的系统的诞生，**一致性**的含义被进一步弱化，模糊化。

通过这篇论文，我们旨在通过为分布式系统中存在的一致性概念提供一个结构化的，覆盖面较广的综述，来填补过去40年文献，尤其是存储系统研究中的空白。我们纵观了50多种不同的一致性概念，罗列出了从线性一致性，最终一致性，到弱一致性的概念，并准确给出了其中大部分的定义，尤其是那些之前有歧义的定义。
我们更进一步根据不同一致性概念的语义上的**强弱**，对其进行了部分排序。而且我们相信这些排序对今后的更深入的研究会非常有用。最后，我们将一致性的语义投射到不同的实际系统和研究的原型中。

这篇论文仅限于非事务的语义范围，比如那些单机存储的操作。同样的，这篇论文补足了现有对于事务，数据库一致性语义的研究。

# 1 介绍

面对失败，异步交互、计算和对共享资源的并发访问所带来的与生俱来的挑战，分布式系统的设计者们一直致力于通过提供抽象层或者不同层级的语义模型，来对用户屏蔽这些基础概念。第一眼看来，分布式系统的终极目标似乎很简单，理论上它只需要是一个具有容错性和扩展性的中心化系统。
换句话说，一个理想的分布式系统应该通过分布式和复制来屏蔽错误，提供扩展性，减小延迟，以增强可用性，但与此同时，需要维持中心化系统的简洁，尤其是一致性，需要让系统看起来像是串行访问一样。
如此强一致性的标准可以从早期的一些为现代存储系统打下重要基础的具有开创性意义的工作看到，比如【[Leslie Lamport, 1978](#leslielamport1978), [Leslie Lamport, 1986a](#leslielamport1986a)】【译者注：见引用文献】，
再比如后来进一步定义了一些普遍的，有实践意义的情况，比如**线性一致性**【[Herlihy and Wing, 1990](#herlihyandwing1990)】。

不幸的是，高可用和强一致性，尤其是线性一致性，在现实情况中，是相互冲突的。这些负面的理论结果，比如FLP不可能性定理【[Fischer et al., 1985](#fischeretal1985)】，CAP理论【[Gilbert and Lynch, 2002](#gilbertandlynch2002)】,为分布式系统设计画出了边界。
结论就是，分布式系统的设计者要么放弃高可用性和扩展性，要么降低一致性要求。

近些年，由于商业化，互联网规模系统的大量增加，系统设计者们往往选择可用性而非一致性，这也导致了弱一致性和最终一致性【[Terry et al., 1994](#terryetal1994); [Saito and Shapiro, 2005](#saitoandshapiro2005); [Vogels, 2008](#vogels2008)】概念的诞生。
因此，许多研究都聚焦在这些更弱的语义的理解【[Bailis and Ghodsi, 2013](#bailisandghodsi2013)】，适应【[Bailis et al., 2014](#bailisetal2014)】及代替更强语义【[Helland, 2007](#helland2007)】上。
沿着这条线继续探索，一些工具被设想出来，已试图从解决编程语言层面【[Alvaro et al., 2011](#alvaroetal2011)】，数据对象层面【[Shapiro et al., 2011a](#shapiroetal2011a); [Burckhardt et al., 2012](#burckhardtetal2012)】，
还有数据流层面【[Alvaro et al., 2014](#alvaroetal2014)】解决一致性问题。

在经历了将近40年对各种各样的一致性问题密集的又令人兴奋的研究过后，我们对分布式系统中存在的一致性概念还是缺乏一个结构化的，覆盖面较广的综述，尤其是存储系统。

这篇论文旨在通过对50多种不同的之前比较有歧义的一致性概念，从线性一致性一直到最终弱一致性，进行定义，以填补上述空白。我们更进一步的根据不同一致性概念语义上的强弱，对一致性概念进行了部分排序，而且我们相信这些排序对今后的更深入的研究会非常有用。
最后，我们将一致性的语义投射到不同的实际系统和研究的原型中。
这篇论文仅限于非事务的语义范围，比如那些单机存储的操作。我们研究的重点是越来越流行的非事务型的存储系统，这些系统实现起来相对容易，也有更好的扩展性。同样的，这篇论文补足了现有对于事务，数据库一致性语义的研究【[Adya, 1999](#adya1999)】，但由于篇幅优先，我们讨论的并不多。

本文的结构如下。在第2部分，我们定义了分布式系统的模型，为推演不同的一致性模型建立了一套框架。为了确保我们的工作尽可能全面，我们将我们的分布式模型设计成异步的，也就是说，没有设置计算和通信的时间约束。
我们的框架延续了【[Burckhardt, 2014](#burckhardt2014)】的工作，并通过分布式系统的**历史**和**抽象执行**描述了分布式系统动态的一面。我们定义一次执行为由某些进程触发的一系列在存储对象上的，通过它们的接口进行操作的动作集合。
为了分析**执行**，我们采用了**历史**的概念，也就是一次执行所对应的的操作的集合。通过分析历史上的所有信息，我们能获取到执行的固有的复杂性。
换句话说，我们可以将操作和他们对应的功能关联起来，并分组(比如，用执行操作的进程，操作的对象，或者用他们花费的时间)，或者依据执行过程中建立的动态关系(比如，因果关系)。
更进一步的，抽象执行增加了有序的操作所组成的历史，这些操作又决定了如何解决写冲突，也决定了他们在存储系统中的传播机制。

第3部分讲述了本论文的核心贡献: 一项对于50多种在非事务型存储系统中不同的一致性语义的调查。我们用第2部分锁提供的框架定义了许多模型，也就是使用图片实体上声明式的谓项逻辑语言的组合。
这些定义，反过来能帮助我们根据一致性语义上的强弱(第3部分图1)建立一套分层有序的一致性语义体系。为了更好的可读性，我们也根据一致性语义的特性，简略的总结出了10种不同的**家族**。

在第4部分，我们讨论了围绕着研究一致性问题的相关工作。在接下来的第5部分，我们进行了小结。我们最后总结本文中的所有一致性谓词(附录A)。对于我们工作中提到的所有一致性模型，我们也提供了它们对应的初始的定义，并提供了相关论文和实现(附录B)。
我们相信这篇论文将产生有用的贡献，因为它不仅仅能让分布式系统的研究人员，尤其能让学生，在面对大量的论文时，能很好的进行导览。

# 2 系统模型

在这一章中，我们着重解释了这篇论文后续所讨论的一致性概念中涉及的主要概念。就像【[Lynch and Tuttle, 1989](#lynchandtuttle1989)】和【[Herlihy and Wing, 1990](#herlihyandwing1990)】提到的，我们必须依赖并发对象抽象来定义基础的，静态的系统元素，比如对象和进程。
此外，为了系统中的动态行为，比如执行，我们依据【[Burckhardt, 2014](#burckhardt2014)】建立了计算框架。

## 2.1 一些前置的概念

* 对象和进程

   我们定义一个分布式的系统为一个以IO自动机【[Lynch and Tuttle, 1989](#lynchandtuttle1989)】为模型的，在一个全联通异步通信网络下的，与共享的(并发的)对象进行交互的，进程的有限集合。除非另有说明，进程和共享对象(或者简单的称之为对象)都是正确的，换句话说，他们不会失败。
   每一个进程和对象都有自己唯一的标识。我们定义*ProcessIds*为所有进程标识的集合，*ObjectIds*为所有对象标识的集合。

   另外，每一个对象都有唯一的对象类型。根据类型，对象可以从*Values*集合中取值(为了更好的可读性，我们使用了一种符号化表示：*Values*集合可以隐式地由对象类型参数化)，对象也支持一系列简单的操作类型集合(比如，*OpTypes = {rd,wr,inc,...}*)，这些集合约束了该对象上所有可能的操作。
   为了简便又不失普片性，除非特殊说明，否则下文中锁说的操作不是*reads(rd)*就是*writes(wr)*。换句话说，我们认定所有修改了对象值的操作为一次*write(or update)*操作，相反的，一次获取对象副本当前值，且不会修改它的操作为一次*read*操作。
   我们采用了对象副本，也可以简称为副本的概念，来代指在一个存储系统中为了容错或者提高性能而对为一个的共享对象存储的另一份完全相同的复制品。理论上，同一个共享对象的所有副本在同一时间的值应该完全相同。这种协同协议由共享对象的实现决定。

* 时间

   除非特别说明，我们认为异步计算和通信模型，都是没有计算和通信延迟的。然而，当描述特殊的一致性概念的时候，我们会使用诸如*渐进*和*过时*等词汇。这些词汇是相对*真实世界的时间*来说的。我们定义真实时间域为*Time*，它是一些正实数的集合，也叫*R*<sup>*+*</sup>。

## 2.2 操作，历史和抽象执行

* 操作

   我们定义一次操作为一个进程在一个共享对象上的元组(*proc,type,obj,ival,oval,stime,rtime*):

   * *$proc \in ProcessIds$*，表示一个出发操作的进程id
   * *$type \in OpTypes$*，表示操作类型
   * *$obj \in ObjectIds$*，表示操作的对象id
   * *$ival \in Values$*，表示操作的输入值
   * *$oval \in Values \cup \\{\nabla\\}$*，表示操作的输出值，如果操作没有返回，则为*$\nabla$*
   * *$stime \in Time$*，表示操作触发的时间
   * *$rtime \in Time \cup \\{\Omega\\}$*，表示操作返回的时间，如果操作没有返回，则为*$\Omega$*

   按照惯例，我们使用特殊值 *t ∈ Values* 代表如操作的输入(ival)和写操作的输出(oval)。简单起见，对于给定的操作 *op*，我们定义 *op.par* 来访问元组中的参数 *par* (比方说，*op.type* 代表了操作的类型，*op.ival* 代表了op的输入值)。

* 历史

  一次历史$H$是一个操作的集合。直观上来看，一次历史包含了一次执行所对应的所有操作。进一步的，$H\|\_{wr}$(或$H\|\_{rd}$) 是一次给定的历史$H$的写(或读)操作的集合(举个例子，$H\|\_{wr} = \{ op \in H : op.type = wr \} $)。

  我们更进一步的定义了历史中的元素之间的关系:

  * *rb(returns-before，在...之前返回)* 表示 *H* 上按真实时间优先的自然偏序。形式上: $rb \triangleq \{(a,b):a,b \in H \land a.rtime<b.stime\}$
  * *ss(same-session，同一次会话)* 表示 *H* 上相同进程触发的一组操作的等价关系 - 我们说这些操作属于同一个 *session*。形式上: $ss \triangleq \{(a,b):a,b \in H \land a.proc=b.proc\}$
  * *so(session order，会话顺序)* 表示一个偏序，该偏序定义为: $so \triangleq rb \bigcap ss$
  * *ob(same-object，同一个对象)* 表示 *H* 上对相同对象触发的一组操作的等价关系。形式上: $ob \in \{(a,b):a,b \in H \land a.obj=b.obj\}$
  * *concur* 表示在同一个对象上的所有实时并发的操作的对称的二元关系。形式上: $concur \triangleq ob \setminus rb$

  对于$(a,b) \in rel$，我们有时也用$a \xrightarrow{rel} b$来表示。我们用$rel^{-1}$来表示rel的反向关系。为了更紧密的符号，我们使用二元关系进行推演。
  例如，$rel\|\_{wr->rd}$表示属于rel的所有由一次写和一次读操作组成的操作对。
  此外，如果rel是一个等价关系，我们记$a \approx \_{rel}b \triangleq \lbrack a \xrightarrow{rel} b \rbrack$。
  一个H上的等价关系rel会将H划分成等价类$[a]\_{rel}=\{b \in H:b \approx \_{rel} a\}$
  我们记$H/\approx_{rel}$来表示由rel确定的等价类集合。我们通过使用函数:$H \xrightarrow{} 2^H$表示与一个操作并发的操作集来完善concur关系:

  $$
  \begin{equation}
  Concur(a) \triangleq \{b \in H|_{wr}:(a,b) \in concur\}
  \end{equation}
  $$

* 抽象执行

   我们按照【Burckhardt, [2014](#burckhardt2014)】用抽象执行的概念来为系统执行建模。一次抽象执行是在一次给定的历史H上的一个用H上的两个关系vis和ar所建立的多图$A=(H,vis,ar)$来表示。
   鉴于历史描述了执行的输出，vis和ar，直观的表述了异步环境的不确定性(比如，消息顺序)，和实现方法所带来的约束(比如，冲突恢复策略)。换句话说，vis和ar决定了历史中的操作之间的两两关系，以共同影响最终的输出。
   更具体的说

   * $vis(visibility，可见性)$ 是一个非循环的，自然的，用以表述写操作传播机制的关系。
   直观上，让a对b可见(也可表示为，$a \xrightarrow{vis} b$)的意义为：a操作所带来的影响可以被b操作看见(比如，b可以读到a写入的一个值)
   * $ar(arbitration，仲裁)$ 是历史中所有操作的全序，该全序描述了系统如何解决由并发操作的和不可见的操作产生的冲突。实践中，这种全序可以由多种方式实现:
   采用分布式时钟【Lamport, [1978](leslielamport1978)】或者一致性协议【Birman et al., [1991](#birmanetal1991); Hadzilacos and Toueg, [1994](#hardzilacosandtoueg1994); Lamport, [2001](#lamport2001)】,使用中心化的序列器，或确定性冲突解决机制。

   根据vis的约束不同，在执行过程中，不同的进程会观察到不同的写操作的顺序，我们称之为序列化。

   我们进一步的定义了happens-before(hb)(在XXX之前发生)顺序，它表示了so和vis并集上的传递闭包，表示为:

   $$
   \begin{equation}
   hb \triangleq (so \cup vis)^+
   \end{equation}
   $$

## 2.3 可复制数据类型和返回值一致性

   与其把当前系统的状态定义为由共享对象保存的值的集合【按照Burckhardt, [2014](#burckhardt2014)】，我们采用了一种叫做上下文的图抽象方式，该方式将一个抽象执行的信息进行编码，并映射到给定操作A的可见性(vis)上。
   形式上，给定C代表给定的抽象执行A上的所有操作的上下文集合，我们定义操作op的上下文为:

   $$
   \begin{equation}
   C=cxt(A,op) \triangleq A|_{op,vis^{-1}(op),vis,ar}
   \end{equation}
   $$

   更进一步的，我们引入了可复制数据类型【Burckhardt, [2014](#burckhardt2014)】的概念来定义在分布式系统上实现的共享对象的类型(比如，读/写寄存器，计数器，集合，队列等等)。
   对于每一种可复制数据类型，函数$\mathcal{F}$表示了操作$op \in H$在上下文中的返回值的集合，也可以记做$\mathcal{F}(op,cxt(A,op))$。用$\mathcal{F}$我们可以定义返回结果的一致性:

   $$
   \begin{equation}
   RV_{AL}(\mathcal{F}) \triangleq \forall op \in H : op.oval \in \mathcal{F}(op,cxt(A,op))
   \end{equation}
   $$

   本质上，返回值一致性是抽象执行上的一次断言，该断言保证了一次执行中的任何给定操作的返回值都属于预计返回值集合中。

   给定操作$b \in H$和它的上下文$cxt(A,b)$，让$a=prec(b)$表示在$ar$中b之前最后(唯一)一次操作，以致$a.oval \neq \nabla \land a \in H|_{wr} \cap vis^{-1}(b)$。
   换句话说，$prec(b)$是在由$ar$决定的顺序下$b$之前最后一次可见的写操作。如果没有这样的谦虚操作存在(比如，b是$ar$下的第一个操作)，为了方便起见，我们记$prec(b).ival$的默认值为$\bot$。

   在这篇论文中，我们采用读/写寄存器(也叫做读/写存储)作为参照的可复制数据类型，并用预期返回值方程表达:

   $$
   \begin{equation}
   \mathcal{F}_{reg}(op,cxt(A,op))=prec(op).ival
   \end{equation}
   $$

   需要注意的是，虽说这篇论文的焦点在读写存储上，但定义的一致性断言使用$\mathcal{F}$作为输入，因此我们可以直接扩展到其他可复制数据类型上。

## 2.4 一致性语义

   按照【Burckhardt, [2014](#burckhardt2014)】所说的，我们定义了一致性语义(有时也叫一致性保证)为抽象执行的属性和关系，表达为一阶逻辑断言。我们记$A \vDash \mathcal{P}$来表示一致性断言$\mathcal{P}$在抽象执行A上为真。
   因此，定义一个一致性模型，其实就是列举所有需要的一致性断言，并证明历史，至少其中的一次抽象执行，可以满足所有断言。

   形式上，对于给定的历史$H$和该历史中的所有可能的抽象执行$\mathcal{A}$，我们说该历史$H$满足所有一致性断言$\mathcal{P}_1$,...$\mathcal{P}_n$，当历史可以被扩展成一些抽象执行，并满足如下条件时:

   $$
   \begin{equation}
   H \vDash \mathcal{P}_1 \land \cdot \cdot \cdot \land \mathcal{P}_n \leftrightarrow \exists A \in \mathcal{A} : \mathcal{H}(A)=H \land A \vDash \mathcal{P}_1 \land \cdot \cdot \cdot \land \mathcal{P}_n
   \end{equation}
   $$

   在上述的符号中，对于给定的抽象执行$A=(H,vis,ar)$，$\mathcal{H}(A)$表示$H$。

# 3 非事务性一致性语义

   在这一部分，我们分析调查了采用单独操作作为首选的系统的一致性语义(也叫做，非事务性一致性语义)。这篇文章中剩余的部分所描述的一致性模型都在下图中，该图综合地根据一致性语义的强弱给出了他们之间的偏序关系，同时把一致性模型划分成了不同的"家族"。
   此分类不仅描绘了一致性语义的强弱不同，也根据他们定义的不同归纳出了共通的因素。

   这部分生下来的内容，我们分别调查了不同家族的一致性语义。3.1中介绍了线性一致性和其他的强一致性模型。3.2中介绍了最终一致性和弱一致性。接下来我们分析了PRAM和顺序一致性(3.3)。3.4中介绍了基于会话的模型。3.5中介绍了因果一致性。3.6中讨论了基于旧数据的模型。
   3.7中讨论了基于分支的模型。3.8和3.0中讨论了可调优的和基于每个对象的语义。最后，我们在3.10中分析了基于同步的一致性模型家族。

   ![models](/assets/Hierarchy of non-transactional consistency models.jpg)

   图1: 非事务一致性模型的层级关系。由一致性语义A指向B的有向边表示任何满足B的执行也满足A。带下划线的模型表明有时间上的保证。

## 3.1 线性一致性和与其相关的强一致性语义

   非一致性系统中的最高标准和核心一致性模型就是线性一致性，由【Herlihy and Wing, [1990](herlihyandwing1990)】定义。粗略的讲，线性一致性是一种正确的状况，在该状况下，每一个操作都会在调用和返回之间的某个时间点立即生效。
   线性一致性，也经常非正式的被称作强一致性，长期以来都被认为是分布式存储需要实现的理想正确性。线性一致性具有局部性: 一个可线性化的对象的组合本身也是可线性化的 - 因此，线性一致性是可以被模块化和证明的。

   如此强的语义，尽管很容易用直觉理解，缺非常难以实现。就这一点而言，【Gilbert and Lynch, [2002](#gilbertandlynch2002)】，形式化的证明了CAP理论。
   该理论【Johnson and Thomas, [1975](#johnsonandrobert1975); Davidson et al., [1985](#davidsonetal1985); Coan et al., [1986](#coanetal); Brewer, [2000](#brewer2000)】都非正式的提出过。
   该理论将一个系统在面对网络分区时的维持非凡水准的能力与线性一致性关联起来。简单来说，CAP理论指出，当网络分区发生的时候，一个分布式存储系统必须在可用性和线性一致性中间二选一。

   [Burckhardt, [2014](#burckhardt2014)]将线性一致性分解为3个部分:

   $$
   \begin{equation}
   L_{INEARIZABILITY}(\mathcal{F}) \triangleq S_{INGLE}O_{RDER} \land R_{EAL}T_{IME} \land RV_{AL}(\mathcal{F})
   \end{equation}
   $$

   在这个公式中:

   $$
   \begin{equation}
   S_{INGLE}O_{RDER} \triangleq \exists H' \subseteq \{ op \in H : op.oval = \nabla \} : vis=ar \setminus (H' \times H)
   \end{equation}
   $$

   $$
   \begin{equation}
   R_{EAL}T_{IME} \triangleq rb \subseteq ar
   \end{equation}
   $$

   换句话说，$S_{INGLE}O_{RDER}$利用了一个单一的整体顺序，并定义了$vis$和$ar$，$REALTIME$使得仲裁($ar$)顺应了returns-before偏序($rb$)。
   最后，$RV_{AL}(\mathcal{F})$指定了可复制数据类型的返回值一致性。我们回忆一下公式(5)，在读写存储的例子中，它表示了最后一次写(由$ar$决定)之后的读操作$rd$所读取到的值。

   一个和线性一致性紧密关联的概念，原子寄存器语义，由【Lamport, [1986b](#lamport1986b)】提出。Lamport描述了一个单写多读(SWMR, single-writer multi-reader)的共享寄存器。
   该寄存器是原子的当且仅当每一个不与写操作重叠的读操作都会正确的返回寄存器上的最后一个写入的值，且如果读操作顺序执行的话，他们返回的值应该是一样的。
   本质上，该定义描绘的是在共享寄存器上的一个个时间上的点(线性点)。我们很容易感受到原子性和线性一致性在读写寄存器上是等价的。然而，线性一致性是在普片意义共享数据结构上的更通用的定义，这些数据结构能够支持更多的操作语义。
   除了原子寄存器，Lamport【[1986b](#lamport1986b)】定义了两个在SWMR寄存器上更弱的语义: **safe**和**regular**。在不考虑读写并发的情况下，他们都能保证一个读操作返回最后一个写入的值，就像原子语义一样。
   他们仨的不同之处在于读写并发的时候读操作的返回值。换句话说，**safe**寄存器上，一个和许多写操作并发的读操作可能返回任何值。相反的，在**regular**寄存器上，一个和许多写操作并发的读操作要不返回最近一次完整写操作的值，要不返回与之并发的写操作的值。
   不同如下图所示:

   ![read write concurrency](/assets/read_write concurrency.png)

   *图2: 读写并发示例(时间发生顺序由左至右)。寄存器初始值为0。原子(线性)语义下x只能是0或者1。Regular语义下x可以是0，1或者2。safe语义下x可以是任意值。*

   形式上，**regular**和**safe**语义可以定义为:

   $$
   \begin{equation}
   R_{EGULAR}(\mathcal{F}) \triangleq S_{INGLE}O_{RDER} \land R_{EAL}T_{IME}W_{RITES} \land RV_{AL}(\mathcal{F})
   \end{equation}
   $$

   $$
   \begin{equation}
   S_{AFE}(\mathcal{F}) \triangleq S_{INGLE}O_{RDER} \land R_{EAL}T_{IME}W_{RITES} \land S_{EQ}RV_{AL}(\mathcal{F})
   \end{equation}
   $$

   其中

   $$
   \begin{equation}
   R_{EAL}T_{IME}W_{RITES} \triangleq rb|_{wr \rightarrow op} \subseteq ar
   \end{equation}
   $$

   是仅对写操作的真实时间顺序上的约束。

   $$
   \begin{equation}
   S_{EQ}RV_{AL}(\mathcal{F}) \triangleq \exists op \in H : Concur(op) = \varnothing \Rightarrow op.oval \in \mathcal{F}(op,cxt(A,op))
   \end{equation}
   $$

   约束了与任意写操作并发的读操作的返回值一致性。

## 3.2 弱一致性和最终一致性

   在一致性频谱的另一端是**弱**一致性。尽管这个词在很多文献中都表示任何比顺序一致性更低的一致性模型，
   但最近的论文【Vogels, [2008](#vogels2008); Bermbach and Kuhlenkamp, [2013](#bermbachandkuhlenkamp2013)】给了它一个更加独特，尽管还是很模糊的定义: 一个弱一致性系统不保证读操作能返回最近一次写操作的值。效果上，弱一致性没有顺序保证 - 因此，也不需要同步协议。
   尽管这个模型看上去没什么用，但它却说明了实现同步协议是代价高昂的，副本之间偶尔的交换信息其实已经足够管用了。
   举个例子，一个典型的弱一致性应用就是网络应用中的层层直至浏览器的缓存策略。

   **最终**一致性比弱一致性要略强一些。从字面意思理解，在最终一致性下，如果没有进一步的更新操作，副本之间会逐渐统一成同一份拷贝。
   换句话说，如果没有新的写操作，最终所有读操作都会返回相同的值。最终一致性最初由【Terry et al. [1994](#terryetal1994)】定义，并由【Vogels, [2008](#vogels2008)】通过引入高可用存储系统(也就是CAP理论中的AP系统)在10多年之后发扬光大。
   最终一致性特别适合那些协调实现起来不是很现实，或者实现代价比较高昂的场景(比如，在移动或者广域设置上)【Saito and Shapiro, [2005](#saitoandshapiro2005)】。尽管应用广泛，最终一致性将短时间异常的可能留个给了应用层的开发者 - 也就是所有那些偏离线性一致性执行的理论结果的行为。
   因此，最近有大量的工作都旨在更好的理解一致性模型和其精妙的实现【Bermbach and Tai, [2011](#bermbachandtai2011); Bernstein and Das, [2013](#bernsteinanddas2013); Bailis and Ghodsi, [2013](#bailisandghodsi2013); Bailis et al., [2014](#bailisetal2014)】。
   其核心观点是，最终一致性约束了副本的最终状态(也叫做他们的收敛): 事实上，它并没有提供任何关于操作时效性和顺序的任何保障。【Burckhardt, [2014](#burckhardt2014)】提出了最终一致性形式上的定义:

   $$
   \begin{equation}
   E_{VENTUAL}C_{ONSISTENCY}(\mathcal{F}) \triangleq E_{VENTUAL}V_{ISIBILITY} \land N_{O}C_{IRCULAR}C_{AUSALITY} \land RV_{AL}(\mathcal{F})
   \end{equation}
   $$

   其中，

   $$
   \begin{equation}
   E_{VENTUAL}V_{ISIBILITY} \triangleq \forall a \in H, \forall[f] \in H \approx_{ss}: |\{b \in [f] : (a \xrightarrow{rb} b) \land \lnot (a \xrightarrow{vis} b\}| \lt \infty
   \end{equation}
   $$

   表示最终，操作$op$在完全执行完成之后对于另一个操作$op'$是可见的。

   $$
   \begin{equation}
   N_{O}C_{IRCULAR}C_{AUSALITY} \triangleq acyclic(hb)
   \end{equation}
   $$

   表明非循环的hb关系(公式2中锁定义的)。

   在一个最终一致性的替代定义中，【Shapiro et al., [2011a](#shapiroetal2011a)】从副本集的角度给出了如下说明:

   * 最终交付: 如果一个正确的副本应用了一次写操作$op$，$op$最终会被应用到所有的正确的副本;

   * 收敛: 所有应用了相同写操作的的正确的副本最终会到达相同的状态;

   * 终止: 所有操作完成。

   对于以上最终一致性的定义，【Shapiro et al., [2011a](#shapiroetal2011a)】增加了如下约束:

   * 强收敛: 所有应用了相同写操作的副本拥有相同的状态。

   换句话说，最后这条保证了任意两个应用了相同(可能顺序不同)写操作的副本中的数据完全相同。一个系统如果实现了最终一致性和强收敛，我们则可称之为强最终一致性。

   我们从读操作的角度解读一下强收敛，那就是对于完全一致的可见写操作的集合，读操作会返回相同结果。

   $$
   \begin{equation}
   S_{TRONG}C_{ONVERGENCE} \triangleq \forall a,b \in H|_{rd} : vis^{-1}(a)|_{wr} = vis^{-1}(b)|_{wr} \implies a.oval=b.oval
   \end{equation}
   $$

   然后，强最终一致性可以定义为:

   $$
   \begin{equation}
   S_{TRONG}E_{VENTUAL}C_{ONSISTENCY}(\mathcal{F}) \triangleq E_{VENTUAL}C_{ONSISTENCY}(\mathcal{F}) \land S_{TRONG}C_{ONVERGENCE}
   \end{equation}
   $$

   **静态一致性**【Herlihy and Shavit, [2008](#herlihyandshavit2008)】指的是，如果一个对象停止接收更新(也就是说，静态了)，那么在这个对象上的执行等价于只包含已完成操作的顺序执行。
   尽管这个定义很像最终一致性，但它并不保证终止: 如果一个系统不停止接收更新，那么它不会到达静态，也不会到达副本收敛。根据【Burckhardt, [2014](#burckhardt2014】，我们形式化的定义静态一致性为:

   $$
   \begin{equation}
   Q_{UIESCENT}C_{ONSISTENCY}(\mathcal{F}) \triangleq |H|_{wr}| \lt \infty \implies \exists C \in \mathcal{C} : \forall [f] \in H/ \approx_{ss} : |\{op \in [f] : op.oval \notin \mathcal{F}(op,C)\}| \lt \infty
   \end{equation}
   $$

## 3.3 PRAM和顺序一致性

   管道RAM(PRAM或者先进先出)一致性【Lipton and Sandberg, [1988](#liptonandsandberg1988)】规定，所有进程看见的由一个进程产生的写操作的顺序，应该和该进程实际执行这些写操作的顺序保持一致。
   另一方面，进程观察到的其他不同进程所执行的写操作的顺序可以不同。也就是说，在这种一致性下，并没有要求有一个全局一致的操作顺序，而由一个指定进程产生的所有写操作必须有序，就想他们在一条管道中一样，PRAM也因此得名。
   我们通过要求可见的偏序(vis)是会话顺序(so)的一个超集来定义PRAM:

   $$
   \begin{equation}
   PRAM \triangleq so \subseteq vis
   \end{equation}
   $$

   就像【Brzezinski et al. [2003](#brzezinskietal2003)】提到的，PRAM一致性能得到保证当且仅当系统提供读你所写，单调读，单调写保证。这些概念我们将在3.4部分介绍。

   当一个系统实现了顺序一致性，所有的操作在所有的副本上都有相同的顺序，并且每一个进程决定的操作顺序是被保护的。形式上:

   $$
   \begin{equation}
   S_{EQUENTIAL}C_{ONSISTENCY}(\mathcal{F}) \triangleq S_{INGLE}O_{RDER} \land PRAM \land RV_{AL}(\mathcal{F})
   \end{equation}
   $$

   因此，由【Lamport, 1979(#lamport1979)】提出的顺序一致性，更像是一种顺序保证，而不是时效性保证。
   像线性一致性一样，顺序一致性强制了操作的全局通用顺序。和线性一致性不同的是，顺序一致性不要求操作在不同的会话间保证真实时间的顺序，而只要在同一个进程中执行操作的真实时间顺序得到保证(就像PRAM一致性一样)。
   一个顺序一致性和线性一致性能力及实现的代价的定量对比，由【Attiya and Welch, [1994](#attiyaandwelch1994)】提出。

   ![3](/assets/An execution with processes issuing write operations on a shared object.png)

   图3: 在共享对象上执行写操作。黑色的点表示线性一致性的点。

   图3表示一个共享对象上的由两个进程执行的写操作。我们假设这两个进程都在一直执行读操作。每一个进程都会观察到一个特定的写操作顺序。如果我们假设系统实现了PRAM一致性，这两个进程，可能会观察到如下的结果:

   $$
   \begin{equation}
   S_{P_{A}}: W_{1} \phantom{2} W_{2} \phantom{2} W_{3} \phantom{2} W_{5} \phantom{2} W_{4} \phantom{2} W_{7} \phantom{2} W_{6} \phantom{2} W_{8} \tag{S.1}
   \end{equation}
   $$

   $$
   \begin{equation}
   S_{P_{A}}: W_{1} \phantom{2} W_{3} \phantom{2} W_{5} \phantom{2} W_{7} \phantom{2} W_{2} \phantom{2} W_{4} \phantom{2} W_{6} \phantom{2} W_{8} \tag{S.2}
   \end{equation}
   $$

   如果系统实现了顺序一致性，那么$S_{P_{A}}$应该和$S_{P_{B}}$完全一致，并且其他所有写进程都应该尊崇这个顺序。因此，(S.1)或(S.2)都能被接受。另一方面，如果系统实现的事线性一致性，并且按照图3中的黑色点锁表示的顺序的话，应该是:

   $$
   \begin{equation}
   S_{P_{A}}: W_{1} \phantom{2} W_{3} \phantom{2} W_{2} \phantom{2} W_{4} \phantom{2} W_{5} \phantom{2} W_{6} \phantom{2} W_{8} \phantom{2} W_{7} \tag{S.3}
   \end{equation}
   $$

## 3.4 会话内一致性保证(Session guarantees)

   会话内一致性保证由【Terry et al., [1994](#terryetal1994)】提出。尽管此概念最初是用来描述和客户端的会话链接的，但会话内一致性保证也可以适应更宽泛的会话定义中，并可以从进程的角度阐述执行问题。
   我们注意到之前的一些工作也将绘画内一致性保证说成是客户端中心模型(client-centric models)【Tanenbaum and van Steen, [2007](#tanenbaumandvansteen2007)】。

   **单调读(Monotonic reads)** 要求连续的读请求必须反映出一个非递减的写操作集合。也就是说，如果一个进程已经读到了一个对象上的值$v$，任何一个接下去的读操作都不会返回值$v$之前的写入值。
   直观来看，读操作只能在那些发出该读操作的进程已经观察到的写操作都被执行过的副本上进行。
   实际上，我们可以这么描述: 给定三个操作$a,b,c \in H$，如果$a \xrightarrow{vis} b$，且$b \xrightarrow{so} c$，其中$b$和$c$都是读操作，那么$a \xrightarrow{vis} c$，换句话说，$vis$和$so$的传递闭包包含在$vis$中。

   $$
   \begin{equation}
   M_{ONOTONIC}R_{EADS} \triangleq \forall a \in H, \forall b,c \in H|_{rd}: a \xrightarrow{vis} b \land b \xrightarrow{so} c \implies a \xrightarrow{vis} c \triangleq (vis;so|_{rd \rightarrow rd}) \subseteq vis
   \end{equation}
   $$

   **读你所写(Read-your-writes)** 保证(也叫读我所写，【Terry et al., [2013](#terryetal2013); Burckhardt, [2014](#burckhardt2014)】)要求由一个进程产生的读操作只能由已经执行过所有该进程产生的写操作的副本执行。

   $$
   \begin{equation}
   R_{EAD}Y_{OUR}W_{RITES} \triangleq \forall a \in H|_{wr}, \forall b \in H|_{rd}: a \xrightarrow{so} b \implies a \xrightarrow{vis} b \triangleq so|_{wr \rightarrow rd} \subseteq vis
   \end{equation}
   $$

   让我们假设两个进程在同一个共享对象上执行读写操作，如图4所示

   ![4](/assets/An execution with processes issuing read and write operations on a shared object.png)

   图4: 在共享对象上执行读写操作

   给定该执行，如果$P_{A}$和$P_{B}$满足读你所写保证，但又不满足PRAM一致性，我们可能会看到如下的顺序:

   $$
   \begin{equation}
   S_{P_{A}}: W_{1} \phantom{2} W_{3} \phantom{2} W_{4} \phantom{2} W_{2} \tag{S.4}
   \end{equation}
   $$

   $$
   \begin{equation}
   S_{P_{A}}: W_{2} \phantom{2} W_{4} \phantom{2} W_{3} \phantom{2} W_{1} \tag{S.5}
   \end{equation}
   $$

   我们注意到一些文献中的将会话内一致性视为读你所写一致性的一种特殊情况，并可以通过粘性客户端会话来实现。换句话说，进程产生的这些会话都会被指向同一个给定的副本。

   在一个保证**单调写（）**的系统中，会话的一次写操作只能在那些该会话之前的写操作都被执行的副本上执行。换句话说，副本必须按一次会话的写操作申请顺序执行它们。

   $$
   \begin{equation}
   M_{ONOTONIC}W_{RITES} \triangleq \forall a,b \in H|_{wr} : a \xrightarrow{so} b \implies a \xrightarrow{ar} b \triangleq so|_{wr \rightarrow wr} \subseteq ar
   \end{equation}
   $$

   **写后读一致性(Writes-follow-reads)**，有时也叫会话因果，跟读你所写一致性有点相反，它保证了一次会话中的写操作一定在该写操作之前的读操作所看见的所有写操作之后被执行。

   $$
   \begin{equation}
   W_{RITES}F_{OLLOW}R_{EADS} \triangleq \forall a,c \in H|_{wr}, \forall b \in H|_{rd} : a \xrightarrow{vis} b \land b \xrightarrow{so} c \implies a \xrightarrow{ar} c \triangleq (vis;so|_{rd \rightarrow wr}) \subseteq ar
   \end{equation}
   $$

   我们发现一些会话内一致性保证嵌入了一些因果概念，这些概念都包括在由【Brzezinski et al., [2004](#brzezinskietal2004)】提出的因果一致性概念中。我们将在接下来的章节中讨论。

## 3.5 因果模型

   被人们普片认知的分布式系统中的潜在因果关系被包含在了由【Lamport, [1987](#lamport1987)】提出的$在...之前发生(happened-before)$关系中。根据此关系，两个操作$a$和$b$是有序的，当(a)他们都是同一个线程的操作，(b)$b$读取了$a$写入的值，(c)他们是由(a)和/或(b)组成的传递闭包。
   这个通常被定义在消息传递系统中的概念，由【Hutto and Ahamad, [1990](#huttoandahamad1990)】翻译成了共享内存系统的一致性条件。
   潜在的因果关系建立在操作的偏序关系上，也就是我们在公式(2)中提到的$hb$。
   因此，具有潜在因果关系(尽管最恰当的术语应该是"潜在英国关系"，为了简单起见，下文中我们还是称之为"因果关系")的的操作在所有进程看来有相同的顺序，不具有因果关系(也叫因果并发)的操作在所有进程看来可能有不同的顺序。
   换句话说，因果一致性规定了对于有因果关系的操作【Hutto and Ahamad, [1990](#huttoandahamad1990); Ahamad et al., [1995](#ahamadetal1995); Mahajan et al., [2011](#mahajanetal2011)】，所有副本所见的顺序必须相同。
   这种模型可以用两个谓词描述【Burckhardt, [2014](#burckhardt2014)】:

   * $C_{AUSAL}V_{ISIBILITY} \triangleq hb \subseteq vis$

   * $C_{AUSAL}A_{RBITRATION} \triangleq hb \subseteq ar$

   因此，因果一致性可以被定义为:

   $$
   \begin{equation}
   C_{AUSALITY}(\mathcal{F}) \triangleq C_{AUSAL}V_{ISIBILITY} \land C_{AUSAL}A_{RBITRATION} \land RV_{AL}(\mathcal{F})
   \end{equation}
   $$

   图5表示了两个进程读写一个共享对象的执行，箭头表示了操作间的因果关系。
   假设执行遵循PRAM一致性但是不满足因果一致性，我们或许能得到如下的序列:

   $$
   \begin{equation}
   S_{P_{A}}: W_{1} \phantom{2} W_{2} \phantom{2} W_{4} \phantom{2} W_{5} \phantom{2} W_{3} \phantom{2} W_{6} \tag{S.6}
   \end{equation}
   $$

   $$
   \begin{equation}
   S_{P_{B}}: W_{3} \phantom{2} W_{6} \phantom{2} W_{1} \phantom{2} W_{2} \phantom{2} W_{4} \phantom{2} W_{5} \tag{S.7}
   \end{equation}
   $$

   ![5](\assets\An execution with processes issuing operations on a shared object.png)

   图5: 在共享对象上由多进程执行操作。箭头指示了操作间的因果关系。

   最近由【Bailis et al., [2012](#bailisetal2012)】提出的明确的应用层因果关系的使用，是潜在因果关系的一个子集(正如【Bailis et al., [2012](#bailisetal2012)】中所讨论的，应用层因果关系图在广度和深度上都比传统的因果关系更小，因为它只囊括了相关的因果关系，关注于应用层面向用户的一面)，
   应用层因果关系是为了使高可用系统能够花费更小的开销在协调和元数据的维护上。
   此外，因果一致性有一些更进一步的研究，在用户能感受到的正确性和协调的代价之前做出权衡，尤其是在移动应用和多区域副本应用【Lloyd et al., [2011](#lloydetal2011); Bailis et al., [2013](#bailisetal2013); Zawirski et al., [2015](#zawirskietal2015)】。

   **因果+(或者叫收敛因果)** 一致性【Lloyd et al., [2011](#lloydetal2011)】指出，在因果一致性的基础上，所有副本将会最终且独立的解决冲突。事实上，因果并发的写操作可能会产生一些冲突，在收敛因果一致性的系统中也是依赖交换性和结核性函数来处理的。
   本质上，因果+用强收敛性(参见公式(17))强化了因果一致性，这使得所有应用了相同写操作的正确副本都处在相同的状态下。在某种意义下，因果+一致性通过强收敛性强化了因果一致性，就像强最终一致性【Shapiro et al., [2011a](#shapiroetal2011a)】强化了最终一致性。
   因此，因果+一致性可以被表示为:

   $$
   \begin{equation}
   C_{AUSAL+}(\mathcal{F}) \triangleq C_{AUSALITY}(\mathcal{F}) \land S_{TRONG}C_{ONVERGENCE}
   \end{equation}
   $$

   **真实时间因果**一致性由[Mahajan et al., [2011](#mahajanetal2011)]提出，它是一个比因果一致性更严格的条件，它强制使得: 在真实时间上不重叠的因果并发写操作，必须按照他们的真实时间被副本应用。

   $$
   \begin{equation}
   R_{EAL}T_{IME}C_{AUSALITY}(\mathcal{F}) \triangleq C_{AUSALITY}(\mathcal{F}) \land R_{EAL}T_{IME}
   \end{equation}
   $$

   其中$R_{EAL}T_{IME}$的定义在公式(9)中。

   我们觉得，尽管[Lloyd et al., [2011](#lloydetal2011)]认为真实时间因果一致性比因果+一致性要强，但我们认为他们不具有可比性。因为真实时间因果一致性 - 就像[Mahajan et al., [2011](#mahajanetal2011)]定义的那样 - 并没有支持强收敛性。
   当然，你可以设计一个真实时间因果一致性的变种来支持强收敛性。

   [Attiya et al., [2015](#attiyaetal2015)]定义了多值寄存器(MVR, multi-value registers)上的$可观察因果一致性$，它比因果一致性要强，因为它可以暴露进程通过观察推测出的操作间的并发。
   可观察因果一致性也被证明是实现了多寄存器的高可用数据存储上最强的一致性模型。

## 3.6 基于过时的模型

   直觉上来看，基于过时的模型允许读操作返回老的，失效的写入值。这些模型提供比最终一致性更强的保障，但和线性一致性相比却足够"弱"以致于我们可以用更高效的方式实现。在文献中，我们使用两个指标衡量旧: (真实)时间和数据(对象)的版本。

   就我们所掌握的知识，第一个基于时间失效一致性模型的形式化描述是[Singla et al., [1997](#singlaetal1997)]提出**delta**一致性。根据delta一致性，写操作保证在最多$t+delta$个时间单位后可见。
   此外，delta一致性是和一个顺序判定(我们将在3.9中介绍慢内存一致性模型)一起定义的: 由同一个进程写入同一个对象的操作，在所有进程看来都有相同的顺序，但是对于不同进程写入同一个对象的操作来说，并没有要求全局有序。

   类似的，限时一致性(timed consistency)模型[Torres-Rojas et al., [1999](#torresrojasetal1999)]，约定了从开始写入的固定时间之后，读操作返回的数据集。
   特别的，在限时可串行化中，所有读操作都准时发生，也就是说，只要还有已经持续了$\Delta$个时间单位的最新值存在，那么读操作就不会返回比该值还老的值。其中$\Delta$为本次执行的一个参数。
   换句话说，与delta一致性类似，如果一个写请求在时间点t被执行，那么该写请求写入的值，将在t+$\Delta$之前被所有进程所见。

   [Mahajan et al., [2010](#mahajanetal2010)]定义了有界的旧，它的核心思想和定时一致性和delta一致性语义类似: 一个写请求应当在一个固定的时间内被所有进程所见。
   然而，该定义也和周期性的消息相关，这种消息让每一个进程保持都保持其他进程的所有跟新，如果丢失了更新，则会挂起进程。
   delta一致性，限时一致性和有界过时的区别事实上只在于微妙的实现细节上，这些细节源于不同的上下文及他们实践的目的。
   因此，我们可以用形式化的方式描述以上三者:

   $$
   \begin{equation}
   T_{IMED}V_{ISIBILITY}(\Delta) \triangleq \forall a \in H|_{wr}, \forall b \in H, \forall t \in Time: a.rtime = t \land b.stime = t + \Delta \implies a \xrightarrow{vis} b
   \end{equation}
   $$

   **限时因果**一致性[Torres-Rojas and Meneses, [2005](#torresrojasandmeneses2005)]保证了每一个执行都遵循因果一致性的偏序，同时也保证所有读都会在$\Delta$时间内及时返回:

   $$
   \begin{equation}
   T_{IMED}C_{AUSALITY}(\mathcal{F},\Delta) \triangleq C_{AUSALITY}(\mathcal{F}) \land T_{IMED}V_{ISIBILITY}(\Delta)
   \end{equation}
   $$

   正如图1中描述的，根据限时可见，限时因果关系是比因果一致性更强的语义。类似的，限时串行一致性[Torres-Rojas and Meneses, [2005](#torresrojasandmeneses2005)]将真实时间全局顺序保障与限时可串行化约束结合在了一起。
   因此，一个$\Delta$=0的限时串行一致性执行，事实上就是可线性化。

# 引用文献

<a id="leslielamport1978">
* Leslie Lamport. 1978. Time, Clocks, and the Ordering of Events in a Distributed System.
  Communications of the ACM (CACM) 21, 7 (1978), 558–565.

<a id="leslielamport1986a">
* Leslie Lamport. 1986a. On Interprocess Communication. Part I: Basic Formalism. Distributed
  Computing 1, 2 (1986), 77–85.

<a id="herlihyandwing1990">
* Maurice Herlihy and Jeannette M. Wing. 1990. Linearizability: A Correctness Condition for
  Concurrent Objects. ACM Transactions on Programming Languages and Systems (TOPLAS)
  12, 3 (1990), 463–492.

<a id="fischeretal1985">
* Michael J. Fischer, Nancy A. Lynch, and Mike Paterson. 1985. Impossibility of Distributed
  Consensus with One Faulty Process. J. ACM 32, 2 (1985), 374–382. DOI:http://dx.
  doi.org/10.1145/3149.214121

<a id="gilbertandlynch2002">
* Seth Gilbert and Nancy A. Lynch. 2002. Brewer’s conjecture and the feasibility of consistent,
  available, partition-tolerant web services. SIGACT News 33, 2 (2002), 51–59.

<a id="terryetal1994">
* Douglas B. Terry, Alan J. Demers, Karin Petersen, Mike Spreitzer, Marvin Theimer, and Brent B.
  Welch. 1994. Session Guarantees for Weakly Consistent Replicated Data. In Parallel and
  Distributed Information Systems (PDIS). 140–149.

<a id="saitoandshapiro2005">
* Yasushi Saito and Marc Shapiro. 2005. Optimistic replication. Comput. Surveys 37, 1 (2005),
  42–81.

<a id="vogels2008">
* Werner Vogels. 2008. Eventually Consistent. Queue 6, 6 (Oct. 2008), 14–19. DOI:http:
  //dx.doi.org/10.1145/1466443.1466448

<a id="bailisandghodsi2013">
* Peter Bailis and Ali Ghodsi. 2013. Eventual Consistency Today: Limitations, Extensions,
  and Beyond. Queue 11, 3 (March 2013), 20:20–20:32. DOI:http://dx.doi.org/10.
  1145/2460276.2462076

<a id="bailisetal2014">
* Peter Bailis, Alan Fekete, Joseph M. Hellerstein, Ali Ghodsi, and Ion Stoica. 2014. Scalable
  atomic visibility with RAMP transactions. In ACM International Conference on Management
  of Data (SIGMOD), 2014. 27–38. DOI:http://dx.doi.org/10.1145/2588555.
  2588562

<a id="helland2007">
* Pat Helland. 2007. Life beyond Distributed Transactions: an Apostate’s Opinion. In Conference
  on Innovative Data Systems Research (CIDR), 2007. 132–141. http://www.cidrdb.
  org/cidr2007/papers/cidr07p15.pdf

<a id="alvaroetal2011">
* Peter Alvaro, Neil Conway, Joseph M. Hellerstein, and William R. Marczak. 2011. Consistency
  Analysis in Bloom: a CALM and Collected Approach. In Conference on Innovative Data
  Systems Research (CIDR), 2011. 249–260. http://www.cidrdb.org/cidr2011/
  Papers/CIDR11_Paper35.pdf

<a id="shapiroetal2011a">
* Marc Shapiro, Nuno M. Preguic¸a, Carlos Baquero, and Marek Zawirski. 2011a. Conflict-Free
  Replicated Data Types. In Stabilization, Safety, and Security of Distributed Systems (SSS),
  2011. 386–400. DOI:http://dx.doi.org/10.1007/978-3-642-24550-3_29

<a id="burckhardtetal2012">
* Sebastian Burckhardt, Manuel Fahndrich, Daan Leijen, and Benjamin P. Wood. 2012. Cloud ¨
  Types for Eventual Consistency. In Object-Oriented Programming (ECOOP), 2012. 283–307.
  DOI:http://dx.doi.org/10.1007/978-3-642-31057-7_14

<a id="alvaroetal2014">
* Peter Alvaro, Neil Conway, Joseph M. Hellerstein, and David Maier. 2014. Blazes: Coordination
  analysis for distributed programs. In IEEE Conference on Data Engineering (ICDE), 2014.
  52–63. DOI:http://dx.doi.org/10.1109/ICDE.2014.6816639

<a id="adya1999">
* Atul Adya. 1999. Weak Consistency: A Generalized Theory and Optimistic Implementations
  for Distributed Transactions. Ph.D. MIT, Cambridge, MA, USA. Also as Technical Report
  MIT/LCS/TR-786.

<a id="burckhardt2014">
* Sebastian Burckhardt. 2014. Principles of Eventual Consistency. Foundations and Trends in
  Programming Languages, Vol. 1. now publishers. 1–150 pages. http://research.
  microsoft.com/apps/pubs/default.aspx?id=230852

<a id="lynchandtuttle1989">
* Nancy A. Lynch and Mark R. Tuttle. 1989. An introduction to input/output automata. CWI
  Quarterly 2 (1989), 219–246.

<a id="herlihyandwing1990">
* Maurice Herlihy and Jeannette M. Wing. 1990. Linearizability: A Correctness Condition for
  Concurrent Objects. ACM Transactions on Programming Languages and Systems (TOPLAS)
  12, 3 (1990), 463–492.

<a id="lynchandtuttle1989">
* Nancy A. Lynch and Mark R. Tuttle. 1989. An introduction to input/output automata. CWI
  Quarterly 2 (1989), 219–246.

<a id="birmanetal1991">
* Kenneth Birman, Andre Schiper, and Pat Stephenson. 1991. Lightweight causal and atomic group
  multicast. ACM Transactions on Computer Systems (TOCS) 9, 3 (1991), 272–314.

<a id="hardzilacosandtoueg1994">
* Vassos Hadzilacos and Sam Toueg. 1994. A modular approach to fault-tolerant broadcasts and
  related problems. Technical Report. Cornell University, Department of Computer Science.

<a id="lamport2001">
* Leslie Lamport. 2001. Paxos Made Simple. SIGACT News 32, 4 (2001), 51–58. DOI:http:
  //dx.doi.org/10.1145/568425.568433

<a id="johnsonandrobert1975">
* Paul R. Johnson and Robert H. Thomas. 1975. Maintenance of duplicate databases. RFC
  677. RFC Editor. http://www.rfc-editor.org/rfc/rfc677.txt http://
  www.rfc-editor.org/rfc/rfc677.txt.

<a id="davidsonetal1985">
* Susan B. Davidson, Hector Garcia-Molina, and Dale Skeen. 1985. Consistency in Partitioned
  Networks. Comput. Surveys 17, 3 (1985), 341–370.

<a id="coanetal">
* Brian A. Coan, Brian M. Oki, and Elliot K. Kolodner. 1986. Limitations on Database Availability
  when Networks Partition. In ACM Symposium on Principles of Distributed Computing, 1986.
  187–194. DOI:http://dx.doi.org/10.1145/10590.10606

<a id="brewer2000">
* Eric A. Brewer. 2000. Towards robust distributed systems (abstract). In ACM Symposium on
  Principles of Distributed Computing (PODC), 2000. 7. DOI:http://dx.doi.org/10.
  1145/343477.343502

<a id="lamport1986b">
* Leslie Lamport. 1986b. On Interprocess Communication. Part II: Algorithms. Distributed
  Computing 1, 2 (1986), 86–101.

<a id="bermbachandkuhlenkamp2013">
* David Bermbach and Jorn Kuhlenkamp. 2013. Consistency in Distributed Storage Systems - An ¨
  Overview of Models, Metrics and Measurement Approaches. In Networked Systems (NETYS),
  2013. 175–189.

<a id="bermbachandtai2011">
* David Bermbach and Stefan Tai. 2011. Eventual Consistency: How Soon is Eventual? An
  Evaluation of Amazon S3’s Consistency Behavior. In Workshop on Middleware for Service
  Oriented Computing (MW4SOC ’11). ACM, New York, NY, USA, 1:1–1:6. DOI:http:
  //dx.doi.org/10.1145/2093185.2093186

<a id="bernsteinanddas2013">
* Philip A. Bernstein and Sudipto Das. 2013. Rethinking eventual consistency. In ACM SIGMOD
  International Conference on Management of Data (SIGMOD), 2013. 923–928. DOI:http:
  //dx.doi.org/10.1145/2463676.2465339

<a id="herlihyandshavit2008">
* Maurice Herlihy and Nir Shavit. 2008. The art of multiprocessor programming. Morgan
  Kaufmann. I–XX, 1–508 pages.

<a id="liptonandsandberg1988">
* Richard J. Lipton and Jonathan S. Sandberg. 1988. PRAM: A scalable shared memory. Technical
  Report CS-TR-180-88. Princeton University.

<a id="lamport1979">
* Leslie Lamport. 1979. How to Make a Multiprocessor Computer That Correctly Executes
  Multiprocess Programs. IEEE Trans. Comput. 28, 9 (1979), 690–691.

<a id="tanenbaumandvansteen2007">
* Andrew S. Tanenbaum and Maarten van Steen. 2007. Distributed systems - principles and
  paradigms (2. ed.). Pearson Education. I–XVIII, 1–686 pages.

<a id="terryetal2013">
* Douglas B. Terry, Vijayan Prabhakaran, Ramakrishna Kotla, Mahesh Balakrishnan, Marcos K.
  Aguilera, and Hussam Abu-Libdeh. 2013. Consistency-based service level agreements for
  cloud storage. In ACM Symposium on Operating Systems Principles (SOSP), 2013. 309–324.

<a id="huttoandahamad1990">
* Phillip W. Hutto and Mustaque Ahamad. 1990. Slow Memory: Weakening Consistency to
  Enchance Concurrency in Distributed Shared Memories. In International Conference on
  Distributed Computing Systems (ICDCS). 302–309.

<a id="ahamadetal1995">
* Mustaque Ahamad, Gil Neiger, James E. Burns, Prince Kohli, and Phillip W. Hutto. 1995. Causal
  Memory: Definitions, Implementation, and Programming. Distributed Computing 9, 1 (1995),
  37–49.

<a id="mahajanetal2011">
* Prince Mahajan, Lorenzo Alvisi, and Mike Dahlin. 2011. Consistency, availability, and convergence. Technical Report TR-11-22. Computer Science Department, University of Texas at
  Austin.

<a id="bailis2012">
* Peter Bailis, Alan Fekete, Ali Ghodsi, Joseph M. Hellerstein, and Ion Stoica. 2012. The potential
  dangers of causal consistency and an explicit solution. In ACM Symposium on Cloud Computing
  (SOCC), 2012. 22. DOI:http://dx.doi.org/10.1145/2391229.2391251

<a id="lloydetal2011">
* Wyatt Lloyd, Michael J. Freedman, Michael Kaminsky, and David G. Andersen. 2011. Don’t
  settle for eventual: scalable causal consistency for wide-area storage with COPS. In ACM
  Symposium on Operating Systems Principles (SOSP). 401–416.

<a id="bailisetal2013">
* Peter Bailis, Ali Ghodsi, Joseph M. Hellerstein, and Ion Stoica. 2013. Bolt-on causal consistency.
  In ACM SIGMOD International Conference on Management of Data (SIGMOD), 2013. 761–
  772.

<a id="zawirskietal2015">
* Marek Zawirski, Nuno Preguic¸a, Sergio Duarte, Annette Bieniusa, Valter Balegas, and Marc ´
  Shapiro. 2015. Write Fast, Read in the Past: Causal Consistency for Client-side Applications.
  ACM/IFIP/USENIX Middleware Conference, 2015.

<a id="attiyaetal2015">
* Hagit Attiya, Faith Ellen, and Adam Morrison. 2015. Limitations of Highly-Available EventuallyConsistent Data Stores. In ACM Symposium on Principles of Distributed Computing (PODC),
  2015. ACM, Donostia-San Sebastian, Spain, 385–394. ´ DOI:http://dx.doi.org/10.
  1145/2767386.2767419

<a id="torresrojasetal1999">
* Francisco J. Torres-Rojas, Mustaque Ahamad, and Michel Raynal. 1999. Timed Consistency
  for Shared Distributed Objects. In ACM Symposium on Principles of Distributed Computing
  (PODC), 1999. 163–172.

<a id="mahajanetal2010">
* Prince Mahajan, Srinath T. V. Setty, Sangmin Lee, Allen Clement, Lorenzo Alvisi, Michael
  Dahlin, and Michael Walfish. 2010. Depot: Cloud Storage with Minimal Trust. In Symposium
  on Operating Systems Design and Implementation (OSDI), 2010. 307–322.

<a id="torresrojasandmeneses2005">
* Francisco J. Torres-Rojas and Esteban Meneses. 2005. Convergence Through a Weak Consistency
  Model: Timed Causal Consistency. CLEI electronic journal 8, 2 (2005).